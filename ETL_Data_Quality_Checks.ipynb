{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit\n",
    "\n",
    "# Initialize Spark session with increased memory settings\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DataQualityChecks\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load the fact and dimension tables\n",
    "dq_fact_immigration_table = spark.table(\"fact_immigration_table\")\n",
    "dq_dimension_arrival_date_table = spark.table(\"dimension_arrival_date_table\")\n",
    "dq_dimension_airports_table = spark.table(\"dimension_airports_table\")\n",
    "dq_dimension_demographics_table = spark.table(\"dimension_demographics_table\")\n",
    "#dq_dimension_countries_temperature_table = spark.table(\"dimension_countries_temperature_table\")\n",
    "\n",
    "# Data Quality Checks\n",
    "\n",
    "# 1. Check for Missing Values\n",
    "missing_values_check = lambda df, table_name: df.select([col(c).isNull().alias(c) for c in df.columns]) \\\n",
    "    .withColumn('table', lit(table_name)).limit(100)  # Adjust the limit as needed\n",
    "\n",
    "# 2. Check Data Types\n",
    "data_types_check = lambda df, table_name: df.select([col(c).cast(\"string\").alias(c) for c in df.columns]) \\\n",
    "    .withColumn('table', lit(table_name)).limit(100)  # Adjust the limit as needed\n",
    "\n",
    "# 3. Duplicate Records\n",
    "duplicate_records_check = lambda df, table_name: df.groupBy(df.columns).count().filter(col(\"count\") > 1) \\\n",
    "    .withColumn('table', lit(table_name)).limit(100)  # Adjust the limit as needed\n",
    "\n",
    "# 4. Referential Integrity\n",
    "referential_integrity_check = dq_fact_immigration_table.join(dq_dimension_arrival_date_table,\n",
    "                                                             dq_fact_immigration_table[\"arrive_date\"] == dq_dimension_arrival_date_table[\"arrival_date\"], \"left\") \\\n",
    "    .filter(dq_dimension_arrival_date_table[\"arrival_date\"].isNull()) \\\n",
    "    .withColumn('table', lit(\"fact_immigration_table\")).limit(100)  # Adjust the limit as needed\n",
    "\n",
    "# 5. Data Distribution\n",
    "data_distribution_check = lambda df, column: df.groupBy(column).count() \\\n",
    "    .withColumn('table', lit(df.columns[0])).limit(100)  # Adjust the limit as needed\n",
    "\n",
    "# Example: Check distribution of ages in demographics table\n",
    "age_distribution_check = data_distribution_check(dq_dimension_demographics_table, \"median_age\")\n",
    "\n",
    "# Execute Data Quality Checks\n",
    "data_quality_checks_results = []\n",
    "\n",
    "# Perform checks on each table\n",
    "for table_df, table_name in [\n",
    "    (dq_fact_immigration_table, \"fact_immigration_table\"),\n",
    "    (dq_dimension_arrival_date_table, \"dimension_arrival_date_table\"),\n",
    "    (dq_dimension_airports_table, \"dimension_airports_table\"),\n",
    "    (dq_dimension_demographics_table, \"dimension_demographics_table\")\n",
    "    #,(dq_dimension_countries_temperature_table, \"dimension_countries_temperature_table\")\n",
    "]:\n",
    "    # 1. Check for Missing Values\n",
    "    missing_values_result = missing_values_check(table_df, table_name)\n",
    "    data_quality_checks_results.append(missing_values_result)\n",
    "\n",
    "    # 2. Check Data Types\n",
    "    data_types_result = data_types_check(table_df, table_name)\n",
    "    data_quality_checks_results.append(data_types_result)\n",
    "\n",
    "    # 3. Duplicate Records\n",
    "    duplicate_records_result = duplicate_records_check(table_df, table_name)\n",
    "    data_quality_checks_results.append(duplicate_records_result)\n",
    "\n",
    "# Display Results\n",
    "for result_df in data_quality_checks_results:\n",
    "    # Check if there are any issues before displaying\n",
    "    if result_df.count() > 0:\n",
    "        table_name = result_df.select('table').distinct().collect()[0]['table']\n",
    "        print(f\"Data Quality Checks passed for {table_name}:\")\n",
    "        result_df.show(5)\n",
    "\n",
    "# Stop Spark session\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
